# 模型说明文档

## 📦 项目现有模型

本项目包含4个预训练模型，位于 `GUI/ptfiles/` 目录下。

### 模型列表

| 模型文件 | 模型类型 | 用途 | 类别数 | 说明 |
|---------|---------|------|--------|------|
| `yolov11-eq.pt` | **坐姿检测专用** | 6类坐姿分类 | 6 | ⭐ **主要使用这个** |
| `yolo11n.pt` | 通用目标检测 | 80类COCO数据集 | 80 | 基础模型 |
| `yolo11n-seg.pt` | 实例分割 | 分割任务 | 80 | 不适合坐姿检测 |
| `yolo11n-pose.pt` | 姿态估计 | 人体关键点检测 | 1 (17个关键点) | 可用于辅助 |

---

## 🎯 模型详细说明

### 1. yolov11-eq.pt（坐姿检测专用模型）⭐

**基本信息：**
- **模型类型**：目标检测（Object Detection）
- **基础架构**：YOLOv11 + MSCA注意力机制
- **训练数据**：坐姿检测专用数据集（MSD）
- **训练轮数**：500 epochs
- **输入尺寸**：640×640

**检测类别（6类）：**
```
0: normal              - 正确坐姿
1: body_left           - 身体左倾
2: body_right          - 身体右倾
3: left_support_head   - 左手托腮
4: right_support_head  - 右手托腮
5: lying_down          - 趴桌
```

**模型特点：**
- ✅ 专门针对坐姿检测任务训练
- ✅ 集成MSCA（多尺度通道注意力）模块
- ✅ 在坐姿数据集上准确率最高
- ✅ 推荐用于实际坐姿检测应用

**适用场景：**
- 实时坐姿监测
- 坐姿健康评估
- 办公/学习场景监控

---

### 2. yolo11n.pt（通用目标检测模型）

**基本信息：**
- **模型类型**：目标检测（Object Detection）
- **基础架构**：YOLOv11-nano
- **训练数据**：COCO数据集
- **输入尺寸**：640×640

**检测类别（80类）：**
```
包含常见物体：
- 人（person）
- 车辆（car, bus, truck等）
- 动物（cat, dog, bird等）
- 家具（chair, table, sofa等）
- 电子设备（laptop, phone, tv等）
等80个类别
```

**模型特点：**
- ✅ 通用目标检测能力
- ✅ 可以检测人，但不能分类坐姿
- ✅ 模型较小，速度快
- ⚠️ 不适合坐姿分类任务

**适用场景：**
- 通用物体检测
- 人员检测
- 作为基线模型对比

---

### 3. yolo11n-seg.pt（实例分割模型）

**基本信息：**
- **模型类型**：实例分割（Instance Segmentation）
- **基础架构**：YOLOv11-nano-seg
- **训练数据**：COCO数据集
- **输入尺寸**：640×640

**功能说明：**
- 不仅检测物体位置，还能分割出物体轮廓
- 输出像素级的分割掩码
- 可以精确区分重叠物体

**模型特点：**
- ✅ 提供精确的物体边界
- ✅ 适合需要精确轮廓的任务
- ⚠️ 不适合坐姿检测（无坐姿类别）
- ⚠️ 计算量较大，速度较慢

**适用场景：**
- 需要精确物体边界的任务
- 图像编辑和处理
- 不推荐用于坐姿检测

---

### 4. yolo11n-pose.pt（姿态估计模型）

**基本信息：**
- **模型类型**：姿态估计（Pose Estimation）
- **基础架构**：YOLOv11-nano-pose
- **训练数据**：COCO Keypoints数据集
- **输入尺寸**：640×640

**检测内容：**
- 检测人体（1个类别）
- 输出17个人体关键点坐标

**17个关键点：**
```
0: 鼻子 (nose)
1-2: 左右眼 (left/right eye)
3-4: 左右耳 (left/right ear)
5-6: 左右肩 (left/right shoulder)
7-8: 左右肘 (left/right elbow)
9-10: 左右腕 (left/right wrist)
11-12: 左右髋 (left/right hip)
13-14: 左右膝 (left/right knee)
15-16: 左右踝 (left/right ankle)
```

**模型特点：**
- ✅ 提供人体姿态信息
- ✅ 可以辅助坐姿分析
- ✅ 可以检测身体倾斜角度
- ⚠️ 不直接输出坐姿类别

**适用场景：**
- 人体姿态分析
- 辅助坐姿检测
- 运动分析

---

## 🔄 模型对比实验建议

### 实验1：专用模型 vs 通用模型
```
对比：yolov11-eq.pt vs yolo11n.pt
目的：验证专用模型在坐姿检测任务上的优势
指标：准确率、精确率、召回率、F1-Score
```

### 实验2：目标检测 vs 姿态估计
```
对比：yolov11-eq.pt vs yolo11n-pose.pt
目的：对比不同任务类型的模型表现
指标：准确率、FPS、适用性
```

### 实验3：有无MSCA模块
```
对比：yolov11-eq.pt vs yolo11n.pt
目的：验证MSCA注意力机制的贡献
指标：准确率提升、检测细节
```

---

## 🚀 模型使用方法

### 在GUI中切换模型

1. **启动程序**
   ```bash
   cd GUI
   python main.py
   ```

2. **切换模型**
   - 在GUI界面顶部找到"模型选择"下拉框
   - 选择想要使用的模型
   - 系统会自动加载新模型

3. **查看效果**
   - 导入图片/视频
   - 点击"开始检测"
   - 对比不同模型的检测结果

### 在代码中使用模型

```python
from ultralytics import YOLO

# 加载坐姿检测模型
model = YOLO('GUI/ptfiles/yolov11-eq.pt')

# 进行预测
results = model.predict('test_image.jpg')

# 获取检测结果
for result in results:
    boxes = result.boxes  # 检测框
    names = result.names  # 类别名称
    print(f"检测到的坐姿: {names}")
```

---

## 📊 模型性能参考

### yolov11-eq.pt（坐姿检测专用）

| 指标 | 数值 | 说明 |
|------|------|------|
| mAP@0.5 | ~90% | 在测试集上的平均精度 |
| FPS (GPU) | 30-50 | NVIDIA GTX 1660及以上 |
| FPS (CPU) | 5-10 | Intel i5及以上 |
| 模型大小 | ~6MB | 轻量级模型 |
| 参数量 | ~2.6M | 适合边缘设备 |

### yolo11n.pt（通用检测）

| 指标 | 数值 | 说明 |
|------|------|------|
| mAP@0.5 | ~37% | COCO数据集 |
| FPS (GPU) | 40-60 | 速度较快 |
| FPS (CPU) | 8-15 | CPU性能较好 |
| 模型大小 | ~6MB | 轻量级 |

### yolo11n-pose.pt（姿态估计）

| 指标 | 数值 | 说明 |
|------|------|------|
| mAP@0.5 | ~50% | 关键点检测精度 |
| FPS (GPU) | 25-40 | 计算量较大 |
| FPS (CPU) | 4-8 | CPU较慢 |
| 模型大小 | ~6MB | 轻量级 |

---

## 🔧 模型优化建议

### 参数优化（不需要重新训练）

1. **IOU阈值调整**
   - 默认值：0.45
   - 建议范围：0.3-0.7
   - 影响：重复检测的过滤

2. **置信度阈值调整**
   - 默认值：0.25
   - 建议范围：0.1-0.5
   - 影响：检测结果的可信度

3. **推理尺寸调整**
   - 默认值：640×640
   - 可选值：320, 480, 640, 800
   - 影响：速度与精度的平衡

### 使用建议

**推荐配置（高精度）：**
```python
model.conf = 0.35  # 提高置信度阈值
model.iou = 0.55   # 提高IOU阈值
imgsz = 640        # 使用标准尺寸
```

**推荐配置（高速度）：**
```python
model.conf = 0.25  # 使用默认值
model.iou = 0.45   # 使用默认值
imgsz = 480        # 降低输入尺寸
```

---

## 📝 注意事项

1. **模型选择**
   - 坐姿检测任务请使用 `yolov11-eq.pt`
   - 其他模型仅用于对比实验

2. **性能要求**
   - GPU推荐：NVIDIA GTX 1660及以上
   - CPU推荐：Intel i5及以上
   - 内存推荐：8GB及以上

3. **输入要求**
   - 图片格式：jpg, png, bmp等
   - 视频格式：mp4, avi, mkv等
   - 分辨率：建议640×640或以上

4. **检测效果**
   - 光照充足的环境效果最佳
   - 避免严重遮挡
   - 保持摄像头稳定

---

## 🔗 相关资源

- **YOLOv11官方文档**：https://docs.ultralytics.com/
- **MSCA论文**：SegNeXt (NeurIPS 2022)
- **数据集下载**：见README.md
- **模型下载**：见README.md

---

## 📞 技术支持

如有问题，请查看：
1. README.md - 项目说明
2. 快速启动指南.md - 使用教程
3. GitHub Issues - 问题反馈

---

**最后更新时间**：2024年12月27日
